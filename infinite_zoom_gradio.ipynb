{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBE5yk4uPD2q",
        "outputId": "6953590c-58aa-449a-b973-ba37ead24195"
      },
      "outputs": [],
      "source": [
        "%pip install gradio\n",
        "%pip install -qq transformers scipy ftfy accelerate\n",
        "%pip install -qq --upgrade diffusers[torch]\n",
        "!git clone https://huggingface.co/spaces/mindart/infinite-zoom-stable-diffusion\n",
        "import sys\n",
        "sys.path.extend(['infinite-zoom-stable-diffusion/'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MJv55nPPTXY"
      },
      "outputs": [],
      "source": [
        "from helpers.image import *\n",
        "from helpers.video import *\n",
        "from diffusers import StableDiffusionInpaintPipeline, DPMSolverMultistepScheduler\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import time\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "inpaint_model_list = [\n",
        "    \"stabilityai/stable-diffusion-2-inpainting\",\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    \"parlance/dreamlike-diffusion-1.0-inpainting\",\n",
        "    \"ghunkins/stable-diffusion-liberty-inpainting\",\n",
        "    \"ImNoOne/f222-inpainting-diffusers\"\n",
        "]\n",
        "default_prompt = \"A psychedelic jungle with trees that have glowing, fractal-like patterns, Simon stalenhag poster 1920s style, street level view, hyper futuristic, 8k resolution, hyper realistic\"\n",
        "default_negative_prompt = \"frames, borderline, text, charachter, duplicate, error, out of frame, watermark, low quality, ugly, deformed, blur\"\n",
        "# TODO:\n",
        "# prompts = {\n",
        "#     0: \"prompt1\",\n",
        "#     7: \"prompt2\"\n",
        "# }\n",
        "\n",
        "custom_init_image = False\n",
        "init_image_address = \"/init/image.jpeg\"\n",
        "\n",
        "\n",
        "def zoom(\n",
        "    model_id,\n",
        "    prompt,\n",
        "    negative_prompt,\n",
        "    num_outpainting_steps,\n",
        "    guidance_scale,\n",
        "    num_inference_steps,\n",
        "):\n",
        "\n",
        "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "        model_id,\n",
        "        torch_dtype=torch.float16,\n",
        "    )\n",
        "    pipe.scheduler = DPMSolverMultistepScheduler.from_config(\n",
        "        pipe.scheduler.config)\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    def no_check(images, **kwargs):\n",
        "        return images, False\n",
        "    pipe.safety_checker = no_check\n",
        "    pipe.enable_attention_slicing()\n",
        "    g_cuda = torch.Generator(device='cuda')\n",
        "\n",
        "    height = 512\n",
        "    width = height\n",
        "\n",
        "    current_image = Image.new(mode=\"RGBA\", size=(height, width))\n",
        "    mask_image = np.array(current_image)[:, :, 3]\n",
        "    mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "    current_image = current_image.convert(\"RGB\")\n",
        "\n",
        "    init_images = pipe(prompt=prompt,  # TODO: prompt=prompts[max(k for k in prompts.keys() if k >= 0)],\n",
        "                       negative_prompt=negative_prompt,\n",
        "                       image=current_image,\n",
        "                       guidance_scale=guidance_scale,\n",
        "                       height=height,\n",
        "                       width=width,\n",
        "                       mask_image=mask_image,\n",
        "                       num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "    mask_width = 128\n",
        "    num_interpol_frames = 30\n",
        "    if (custom_init_image):\n",
        "        current_image = load_img(init_image_address, (width, height))\n",
        "    else:\n",
        "        current_image = init_images[0]\n",
        "\n",
        "    all_frames = []\n",
        "    all_frames.append(current_image)\n",
        "\n",
        "    for i in range(num_outpainting_steps):\n",
        "        print('Outpaint step: ' + str(i+1) +\n",
        "              ' / ' + str(num_outpainting_steps))\n",
        "\n",
        "        prev_image_fix = current_image\n",
        "\n",
        "        prev_image = shrink_and_paste_on_blank(current_image, mask_width)\n",
        "\n",
        "        current_image = prev_image\n",
        "\n",
        "        # create mask (black image with white mask_width width edges)\n",
        "        mask_image = np.array(current_image)[:, :, 3]\n",
        "        mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "\n",
        "        # inpainting step\n",
        "        current_image = current_image.convert(\"RGB\")\n",
        "        images = pipe(prompt=prompt,  # TODO: prompt=prompts[max(k for k in prompts.keys() if k <= i)],\n",
        "                      negative_prompt=negative_prompt,\n",
        "                      image=current_image,\n",
        "                      guidance_scale=guidance_scale,\n",
        "                      height=height,\n",
        "                      width=width,\n",
        "                      # generator = g_cuda.manual_seed(seed),\n",
        "                      mask_image=mask_image,\n",
        "                      num_inference_steps=num_inference_steps)[0]\n",
        "        current_image = images[0]\n",
        "        current_image.paste(prev_image, mask=prev_image)\n",
        "\n",
        "        # interpolation steps bewteen 2 inpainted images (=sequential zoom and crop)\n",
        "        for j in range(num_interpol_frames - 1):\n",
        "            interpol_image = current_image\n",
        "            interpol_width = round(\n",
        "                (1 - (1-2*mask_width/height)**(1-(j+1)/num_interpol_frames))*height/2\n",
        "            )\n",
        "            interpol_image = interpol_image.crop((interpol_width,\n",
        "                                                  interpol_width,\n",
        "                                                  width - interpol_width,\n",
        "                                                  height - interpol_width))\n",
        "\n",
        "            interpol_image = interpol_image.resize((height, width))\n",
        "\n",
        "            # paste the higher resolution previous image in the middle to avoid drop in quality caused by zooming\n",
        "            interpol_width2 = round(\n",
        "                (1 - (height-2*mask_width) / (height-2*interpol_width)) / 2*height\n",
        "            )\n",
        "            prev_image_fix_crop = shrink_and_paste_on_blank(\n",
        "                prev_image_fix, interpol_width2)\n",
        "            interpol_image.paste(prev_image_fix_crop, mask=prev_image_fix_crop)\n",
        "\n",
        "            all_frames.append(interpol_image)\n",
        "\n",
        "        all_frames.append(current_image)\n",
        "\n",
        "    video_file_name = \"infinite_zoom_\" + str(time.time())\n",
        "    fps = 30\n",
        "    save_path = video_file_name + \".mp4\"\n",
        "    start_frame_dupe_amount = 15\n",
        "    last_frame_dupe_amount = 15\n",
        "\n",
        "    write_video(save_path, all_frames, fps, False,\n",
        "                start_frame_dupe_amount, last_frame_dupe_amount)\n",
        "    return save_path\n",
        "\n",
        "\n",
        "def zoom_app():\n",
        "    with gr.Blocks():\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "\n",
        "                outpaint_prompt = gr.Textbox(\n",
        "                    lines=1,\n",
        "                    value=default_prompt,\n",
        "                    label='Prompt'\n",
        "                )\n",
        "\n",
        "                outpaint_negative_prompt = gr.Textbox(\n",
        "                    lines=1,\n",
        "                    value=default_negative_prompt,\n",
        "                    label='Negative Prompt'\n",
        "                )\n",
        "\n",
        "                outpaint_steps = gr.Slider(\n",
        "                    minimum=5,\n",
        "                    maximum=25,\n",
        "                    step=1,\n",
        "                    value=12,\n",
        "                    label='Total Outpaint Steps'\n",
        "                )\n",
        "                with gr.Accordion(\"Advanced Options\", open=False):\n",
        "                    model_id = gr.Dropdown(\n",
        "                        choices=inpaint_model_list,\n",
        "                        value=inpaint_model_list[0],\n",
        "                        label='Pre-trained Model ID'\n",
        "                    )\n",
        "\n",
        "                    guidance_scale = gr.Slider(\n",
        "                        minimum=0.1,\n",
        "                        maximum=15,\n",
        "                        step=0.1,\n",
        "                        value=7,\n",
        "                        label='Guidance Scale'\n",
        "                    )\n",
        "\n",
        "                    sampling_step = gr.Slider(\n",
        "                        minimum=1,\n",
        "                        maximum=100,\n",
        "                        step=1,\n",
        "                        value=50,\n",
        "                        label='Sampling Steps for each outpaint'\n",
        "                    )\n",
        "\n",
        "                generate_btn = gr.Button(value='Generate video')\n",
        "\n",
        "            with gr.Column():\n",
        "                output_image = gr.Video(label='Output', format=\"mp4\").style(\n",
        "                    width=512, height=512)\n",
        "\n",
        "        generate_btn.click(\n",
        "            fn=zoom,\n",
        "            inputs=[\n",
        "                model_id,\n",
        "                outpaint_prompt,\n",
        "                outpaint_negative_prompt,\n",
        "                outpaint_steps,\n",
        "                guidance_scale,\n",
        "                sampling_step\n",
        "            ],\n",
        "            outputs=output_image,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhb-wxESGFGc"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "app = gr.Blocks()\n",
        "with app:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "        <h3 style='text-align: center'>\n",
        "       Text to Video - Infinite zoom effect\n",
        "        </h3>\n",
        "        \"\"\"\n",
        "    )\n",
        "    zoom_app()\n",
        "\n",
        "app.launch(share=True,debug=True,enable_queue=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
