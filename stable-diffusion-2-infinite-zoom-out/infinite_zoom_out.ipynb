{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalintKomjati/infinite-loop/blob/main/stable-diffusion-2-infinite-zoom-out/infinite_zoom_out.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown CHECK TYPE OF GPU AND VRAM AVAILABLE   <br>\n",
        "#@markdown The notebook should work with the Tesla T4 GPU + 16 GB VRAM available in the free colab tier.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "oIZQ7ADVr8Bf",
        "outputId": "47f14829-11bd-4e5a-fe3b-fcb341e5494c"
      },
      "id": "oIZQ7ADVr8Bf",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15109 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown INSTALL MISSING LIBRARIES\n",
        "%pip install -qq transformers scipy ftfy accelerate\n",
        "%pip install -qq --upgrade diffusers[torch]"
      ],
      "metadata": {
        "id": "0qeBB8hL7Rw8",
        "cellView": "form"
      },
      "id": "0qeBB8hL7Rw8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b1c5bbf0-b5ed-4daf-a6a4-127d3ac044a2",
      "metadata": {
        "id": "b1c5bbf0-b5ed-4daf-a6a4-127d3ac044a2",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown LOAD LIBRARIES\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e93fecd4-fc49-448d-8ca0-52cde5d075da",
      "metadata": {
        "id": "e93fecd4-fc49-448d-8ca0-52cde5d075da",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown DEFINE HELPER FUNCTIONS\n",
        "def write_video(file_path, frames, fps, reversed = True):\n",
        "    \"\"\"\n",
        "    Writes frames to an mp4 video file\n",
        "    :param file_path: Path to output video, must end with .mp4\n",
        "    :param frames: List of PIL.Image objects\n",
        "    :param fps: Desired frame rate\n",
        "    :param reversed: if order of images to be reversed (default = True)\n",
        "    \"\"\"\n",
        "    if reversed == True:\n",
        "      frames.reverse()\n",
        "\n",
        "    w, h = frames[0].size\n",
        "    fourcc = cv2.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
        "    #fourcc = cv2.VideoWriter_fourcc(*'avc1')\n",
        "    writer = cv2.VideoWriter(file_path, fourcc, fps, (w, h))\n",
        "\n",
        "    for frame in frames:\n",
        "        np_frame = np.array(frame.convert('RGB'))\n",
        "        cv_frame = cv2.cvtColor(np_frame, cv2.COLOR_RGB2BGR)\n",
        "        writer.write(cv_frame)\n",
        "\n",
        "    writer.release() \n",
        "\n",
        "def image_grid(imgs, rows, cols):\n",
        "  assert len(imgs) == rows*cols\n",
        "\n",
        "  w, h = imgs[0].size\n",
        "  grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "  grid_w, grid_h = grid.size\n",
        "\n",
        "  for i, img in enumerate(imgs):\n",
        "      grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "  return grid\n",
        "\n",
        "def shrink_and_paste_on_blank(current_image, STEPSIZE):\n",
        "\n",
        "  height = current_image.height\n",
        "  width = current_image.width\n",
        "\n",
        "  #shrink down by STEPSIZE\n",
        "  prev_image = current_image.resize((height-2*STEPSIZE,width-2*STEPSIZE))\n",
        "  prev_image = prev_image.convert(\"RGBA\")\n",
        "  prev_image = np.array(prev_image)\n",
        "\n",
        "  #create blank non-transparent image\n",
        "  blank_image = np.array(current_image.convert(\"RGBA\"))*0\n",
        "  blank_image[:,:,3] = 1\n",
        "\n",
        "  #paste shrinked onto blank\n",
        "  blank_image[STEPSIZE:height-STEPSIZE,STEPSIZE:width-STEPSIZE,:] = prev_image\n",
        "  prev_image = Image.fromarray(blank_image)\n",
        "\n",
        "  return prev_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd",
      "metadata": {
        "id": "bbdb396d-f01c-4b4b-9307-b0f78eaa9ffd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown DOWNLOAD STABLE DIFFUSION OUTPAINTING MODEL AND SET UP DIFFUSION PIPELINE\n",
        "model_id = \"stabilityai/stable-diffusion-2-inpainting\" #@param\n",
        "pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, revision=\"fp16\")\n",
        "#pipe.set_use_memory_efficient_attention_xformers(True) #https://huggingface.co/docs/diffusers/optimization/fp16#memory-efficient-attention #couldnt make it run on colab\n",
        "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "def dummy(images, **kwargs):\n",
        "    return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing() #This is useful to save some memory in exchange for a small speed decrease.\n",
        "\n",
        "g_cuda = torch.Generator(device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e53e31ca-0992-425b-ba26-3906e4a974d6",
      "metadata": {
        "id": "e53e31ca-0992-425b-ba26-3906e4a974d6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown FIND A GOOD CONCEPT: <br>\n",
        "#@markdown (Output of this block will be the last image of the video)\n",
        "\n",
        "orig_prompt = \"A dream of a distant galaxy, concept art, matte painting, HQ, 4k\" #@param\n",
        "orig_negative_prompt = \"blur, blurred, frame, ugly, low quality\" #@param\n",
        "\n",
        "num_images = 1 #@param\n",
        "seed = 9888 #@param\n",
        "num_inference_steps = 20 #@param\n",
        "guidance_scale = 7 #@param\n",
        "height = 1024 #@param\n",
        "width = height #@param\n",
        "\n",
        "\n",
        "prompt = [orig_prompt] * num_images\n",
        "negative_prompt = [orig_negative_prompt] * num_images\n",
        "\n",
        "current_image = PIL.Image.new(mode=\"RGBA\", size=(height, width))\n",
        "mask_image = np.array(current_image)[:,:,3] \n",
        "mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "current_image = current_image.convert(\"RGB\")\n",
        "\n",
        "init_images =  pipe(prompt=prompt,\n",
        "                    negative_prompt=negative_prompt,\n",
        "                    image=current_image,\n",
        "                    guidance_scale = guidance_scale,\n",
        "                    height = height,\n",
        "                    width = width, \n",
        "                    generator = g_cuda.manual_seed(seed),\n",
        "                    mask_image=mask_image, \n",
        "                    num_inference_steps=num_inference_steps)[0]\n",
        "\n",
        "\n",
        "image_grid(init_images, rows=1, cols=num_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62b4aed2-0dae-4c39-a445-5d901e81036e",
      "metadata": {
        "id": "62b4aed2-0dae-4c39-a445-5d901e81036e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown GENERATE VIDEO:  <br> <br>\n",
        "#@markdown Pick an image from the previous block for your video (0 == 1st image, only relevant if num_images > 1)\n",
        "image_num_selected = 0 #@param\n",
        "#@markdown Number of outpainting steps:\n",
        "NUMFRAMES = 10 #@param\n",
        "#@markdown Width of the border in pixels to be outpainted during each step:\n",
        "STEPSIZE = 256 #@param\n",
        "#@markdown Number of frames to be interpolated between each outpainting step\n",
        "NUMINTERPOLFRAMES = 23 #@param \n",
        "#@markdown Note: length of the video ~ NUMFRAMES * NUMOFINTERPOLFRAMES\n",
        "\n",
        "#ideally STEPSIZE should be a power of 2\n",
        "#ideally STEPSIZE / (NUMINTERPOLFRAMES + 1) / 2 should be even\n",
        "\n",
        "current_image = init_images[0]\n",
        "all_frames = []\n",
        "all_frames.append(current_image)\n",
        "\n",
        "for i in range(NUMFRAMES):\n",
        "  print('Generating image: ' + str(i+1) + ' / ' + str(NUMFRAMES))\n",
        "\n",
        "  prev_image_fix = current_image\n",
        "\n",
        "  prev_image = shrink_and_paste_on_blank(current_image, STEPSIZE)\n",
        "\n",
        "  current_image = prev_image\n",
        "\n",
        "  #create mask (black image with white STEPSIZE width edges)\n",
        "  mask_image = np.array(current_image)[:,:,3] \n",
        "  mask_image = Image.fromarray(255-mask_image).convert(\"RGB\")\n",
        "\n",
        "  #inpaint\n",
        "  current_image = current_image.convert(\"RGB\")\n",
        "  images = pipe(prompt=prompt,\n",
        "                negative_prompt=negative_prompt,\n",
        "                image=current_image,\n",
        "                guidance_scale = guidance_scale,\n",
        "                height = height,\n",
        "                width = width, \n",
        "                #generator = g_cuda.manual_seed(seed), #this makes the whole thing deterministic\n",
        "                mask_image=mask_image, \n",
        "                num_inference_steps=num_inference_steps)[0]\n",
        "  current_image = images[0]\n",
        "  current_image.paste(prev_image, mask=prev_image)\n",
        "\n",
        "  #zoom and crop to create interpolated frames between 2 inpainted frames\n",
        "  scalefactor = ((height - 2*STEPSIZE) / height )**(1/(NUMINTERPOLFRAMES+1))\n",
        "  for j in range(NUMINTERPOLFRAMES):\n",
        "    interpol_image = current_image\n",
        "    pix = round((1-(scalefactor**(NUMINTERPOLFRAMES-j)))*height / 2)\n",
        "    interpol_image = interpol_image.crop((pix,\n",
        "                                          pix,\n",
        "                                          width - pix,\n",
        "                                          height - pix))\n",
        "\n",
        "    interpol_image = interpol_image.resize((height, width))\n",
        "\n",
        "    #fix blur in the middle:\n",
        "    pix2 = round((height - (height - 2*STEPSIZE)*height/(height-2*pix))/2)\n",
        "    prev_image_fix_crop = shrink_and_paste_on_blank(prev_image_fix, pix2)\n",
        "    interpol_image.paste(prev_image_fix_crop, mask = prev_image_fix_crop)\n",
        "\n",
        "    all_frames.append(interpol_image)\n",
        "\n",
        "  all_frames.append(current_image)\n",
        "  clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown CHECK SOME (equally spaced) FRAMES OF THE VIDEO:\n",
        "num_of_frames_to_chk = 4 #@param\n",
        "num_of_frames_to_chk = min(num_of_frames_to_chk, len(all_frames))\n",
        "idx = np.round(np.linspace(0, len(all_frames) - 1, num_of_frames_to_chk)).astype(int)\n",
        "image_grid(list(all_frames[i] for i in idx), rows = 1, cols = num_of_frames_to_chk)\n",
        "#@markdown (This is relatively slow but still faster in some cases then to download the complete video in the next block)\n"
      ],
      "metadata": {
        "id": "uGFjrJkTOUZt",
        "cellView": "form"
      },
      "id": "uGFjrJkTOUZt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "377b2064-7c0e-404b-8366-8d03befb840a",
      "metadata": {
        "id": "377b2064-7c0e-404b-8366-8d03befb840a",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown RENDER THE GENERATED FRAMES INTO AN MP4 VIDEO.\n",
        "video_file_name = \"infinite_zoom_out\" #@param\n",
        "write_video(video_file_name + \".mp4\", all_frames, 24)\n",
        "#@markdown Once finished download your video from the \"Files\" folder menu on the left."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO\n",
        "\n",
        " - Simplify interpolation logic (e.g. scalefactor * pix)\n",
        " - Refactor: \"fix blur in the middle\" == 1st steps in the outer loop\n",
        " - Tweak seed (fixed for some frames then shift + det vs nondet)\n",
        " - Tweak prompts (drift between prompts)\n",
        " - 1024 res\n"
      ],
      "metadata": {
        "id": "oa0Hww30NfUJ"
      },
      "id": "oa0Hww30NfUJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21fe434c-9454-4cca-9ca4-55b24535001f",
      "metadata": {
        "id": "21fe434c-9454-4cca-9ca4-55b24535001f"
      },
      "outputs": [],
      "source": [
        "#frame_one = all_frames[0]\n",
        "#frame_one.save(\"all_frames.gif\", format=\"GIF\", append_images=all_frames[1:], save_all=True, duration=250, loop=0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}